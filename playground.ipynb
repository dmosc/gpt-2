{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61678d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from modules import LanguageModel\n",
    "from modules.optimizers import AdamW\n",
    "from utils import Checkpointer, Tokenizer\n",
    "from pathlib import Path\n",
    "from modules.schedulers import CosAnnealingScheduler\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.load()\n",
    "# Model config.\n",
    "d_model = 128\n",
    "num_heads = 8\n",
    "d_ff = int(8 / 3 * d_model)\n",
    "vocab_size = len(tokenizer.vocab)\n",
    "max_seq_len = 1024\n",
    "num_layers = 4\n",
    "model = LanguageModel(d_model, num_heads, d_ff, vocab_size, max_seq_len,\n",
    "                      num_layers)\n",
    "\n",
    "# Optimizer config.\n",
    "max_lr = 3e-3\n",
    "min_lr = 1e-3\n",
    "warmup_steps = 20\n",
    "max_steps = 100\n",
    "scheduler = CosAnnealingScheduler(max_lr, min_lr, warmup_steps, max_steps)\n",
    "optimizer = AdamW(list(model.parameters()),\n",
    "                  lr=scheduler.max_lr, weight_decay=0.1)\n",
    "checkpointer = Checkpointer(Path('data/models'))\n",
    "checkpointer.load_checkpoint(model, optimizer, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b09c74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab[b'<|endoftext|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e58ca424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes practice, Lily and Sam was very happy.\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "sequence = 'It takes practice, Lily'\n",
    "max_gen_len = 200\n",
    "end_token = '<|endoftext|>'\n",
    "while max_gen_len:\n",
    "    tokens = torch.tensor(tokenizer.encode(sequence))\n",
    "    next_token = model.generate_next_token(tokens).item()\n",
    "    decoded_next_token = tokenizer.decode([next_token])\n",
    "    if sequence.endswith(end_token):\n",
    "        break\n",
    "    sequence += decoded_next_token\n",
    "    max_gen_len -= 1\n",
    "print(sequence)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
